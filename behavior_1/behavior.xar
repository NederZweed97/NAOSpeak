<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.ald.softbankrobotics.com/schema/choregraphe/project.xsd" xar_version="3">
  <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
    <bitmap>media/images/box/root.png</bitmap>
    <script language="4">
      <content>
        <![CDATA[]]>
      </content>
    </script>
    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
    <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
    <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
    <Timeline enable="0">
      <BehaviorLayer name="behavior_layer1">
        <BehaviorKeyframe name="keyframe1" index="1">
          <Diagram>
            <Box name="Initiation" id="1" localization="8" tooltip="Deze box genereert de content mbv chatGPT. &#x0A;&#x0A;Deze box inititeerd het gesprek, heeft een counter om de hoeveel cycles bij te houden en te reageren op wat de gebruiker tegen de robot zegt. " x="178" y="42">
              <bitmap>media/images/box/box-dialog.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import subprocess
import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.counter = 0
        self.api_key = ''
        self.url = 'https://api.openai.com/v1/chat/completions'
        self.system_message = {"role": "system", "content": "You are an NAO robot that asks an easy short question."}
        self.messages = [self.system_message]

    def onLoad(self):
        pass

    def onUnload(self):
        pass

    def onInput_onStart(self):
        initial_prompt = "Please ask me a question."
        self.onInput_onResponse(initial_prompt)

    def onInput_onResponse(self, user_input):
        self.counter += 1
        print "Counter value:", self.counter

        # End conversation after 4 interactions
        if self.counter == 4:
            self.say("Oops, I think I forgot something, gotta go back to work!")
            self.messages = [self.system_message]
            self.counter = 0
            self.onStopped()
            return

        # Add user input to conversation history
        self.messages.append({"role": "user", "content": user_input})

        # Prepare data payload for OpenAI API
        data = {
            "model": "gpt-3.5-turbo",
            "messages": self.messages,
            "max_tokens": 50
        }

        try:
            # Prepare headers and data for the curl command
            headers = [
                "Content-Type: application/json",
                "Authorization: Bearer {}".format(self.api_key)
            ]
            header_args = ' '.join(['-H "{}"'.format(header) for header in headers])
            data_str = json.dumps(data)

            # Create and execute the curl command
            curl_cmd = 'curl -X POST {url} {headers} --data \'{data}\''.format(
                url=self.url,
                headers=header_args,
                data=data_str
            )
            result = subprocess.Popen(curl_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
            stdout, stderr = result.communicate()

            # Debugging output
            print "Curl stdout:", stdout
            print "Curl stderr:", stderr

            # Check for curl command errors
            if result.returncode != 0:
                raise subprocess.CalledProcessError(result.returncode, curl_cmd, output=stdout, stderr=stderr)

            # Parse the API response
            response_json = json.loads(stdout)
            if 'choices' not in response_json:
                raise KeyError('choices')

            # Extract the generated response from OpenAI and add it to the message history
            generated_text = response_json['choices'][0]['message']['content'].strip()
            print "Generated text:", generated_text
            self.messages.append({"role": "assistant", "content": generated_text})

            # Make the robot say the generated response
            self.onStopped(generated_text)

        except subprocess.CalledProcessError as e:
            print "Curl request failed:", e
            print "Curl stderr:", e.stderr
            self.triggerError("Er is iets fout gegaan. Vraag iemand om hulp.")
        except KeyError as e:
            print "Key error:", e
            print "Response JSON:", response_json
            self.triggerError("Er is iets fout gegaan. Vraag iemand om hulp.")
        except ValueError as e:
            print "JSON decode error:", e
            print "Response text:", stdout
            self.triggerError("Er is iets fout gegaan. Vraag iemand om hulp.")
        except Exception as e:
            print "An unexpected error occurred:", e
            self.triggerError("Er is iets fout gegaan. Vraag iemand om hulp.")

    def onInput_onStop(self):
        self.onUnload()
        self.onStopped()

    def triggerError(self, message):
        print("Error:", message)
        self.onError(message)  # Trigger the error output with the message]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Input name="onRespons" type="3" type_size="1" nature="2" inner="0" tooltip="" id="4" />
              <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="5" />
              <Output name="triggerError" type="3" type_size="1" nature="2" inner="0" tooltip="Output voor foutmledingen" id="6" />
            </Box>
            <Box name="Spreken" id="2" localization="8" tooltip="Laat de robot spreken wat de initiation box heeft gemaakt" x="325" y="52">
              <bitmap>media/images/box/interaction/say.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.tts = self.session().service('ALTextToSpeech')
        self.ttsStop = self.session().service('ALTextToSpeech') #Create another service as wait is blocking if audioout is remote
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.pCall("say",str(sentence))
            self.ids.append(id)
            self.tts.wait(id)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
              <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
              <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
              <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
              <Resource name="Speech" type="Lock" timeout="0" />
            </Box>
            <Box name="Begrijpen" id="4" localization="8" tooltip="Zet de opname om in tekst, en besluit wat te doen." x="618" y="58">
              <bitmap>media/images/box/box-script.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import subprocess
import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        pass  # Initialization code, if needed

    def onUnload(self):
        pass  # Clean-up code, if needed

    def onInput_onStart(self, p):
        api_key = ''
        if not api_key:
            self.triggerError("Er is iets fout gegaan. Vraag iemand om hulp.")
            return

        audio_file_path = p
        url = "https://api.openai.com/v1/audio/transcriptions"
        curl_cmd = (
            'curl -X POST {url} -H "Authorization: Bearer {api_key}" '
            '-H "Content-Type: multipart/form-data" '
            '-F "file=@{file}" -F "model=whisper-1"'.format(
                url=url, api_key=api_key, file=audio_file_path
            )
        )

        print("Curl command:", curl_cmd)

        try:
            result = subprocess.Popen(curl_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
            stdout, stderr = result.communicate()

            # Decode stdout and stderr for further use
            stdout = stdout.decode('utf-8')
            stderr = stderr.decode('utf-8')

            if result.returncode != 0:
                raise subprocess.CalledProcessError(result.returncode, curl_cmd, output=stdout, stderr=stderr)

            response_json = json.loads(stdout)
            transcription_result = response_json.get('text', '').strip()

            if not transcription_result:
                print("Transcription result is empty. Triggering onSilence output.")
                self.onSilence()  # Trigger the onSilence output
            else:
                print("Transcription result:", transcription_result)
                self.onStopped(transcription_result)  # Return the transcription
        except subprocess.CalledProcessError as e:
            print("Curl request failed:", e)
            self.triggerError("Er is iets fout gegaan. Vraag iemand om hulp.")
        except ValueError as e:
            print("JSON decode error:", e)
            self.triggerError("Er is iets fout gegaan. Vraag iemand om hulp.")
        except Exception as e:
            print("An unexpected error occurred:", e)
            self.triggerError("Er is iets fout gegaan. Vraag iemand om hulp.")

    def onInput_onStop(self):
        self.onUnload()
        self.onStopped()  # Trigger the output when the process is stopped

    def triggerError(self, message):
        print("Error:", message)
        self.onError(message)  # Trigger the error output with the message]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
              <Output name="onSilence" type="1" type_size="1" nature="2" inner="0" tooltip="" id="5" />
              <Output name="triggerError" type="3" type_size="1" nature="2" inner="0" tooltip="Output voor foutmledingen" id="6" />
            </Box>
            <Box name="Luisteren" id="7" localization="8" tooltip="De robot neem voor 5 seconden op wat de gebruiker zegt.&#x0A;&#x0A;tijdens het luisteren veranderd de LEDs van de ogen als fedback. Klap deze uit om de oogkleur te veranderen" x="465" y="57">
              <bitmap>media/images/box/interaction/rec_sound.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="input" type="1" type_size="1" nature="2" inner="0" tooltip="" id="2" />
              <Output name="output" type="3" type_size="1" nature="1" inner="0" tooltip="" id="3" />
              <Timeline enable="0">
                <BehaviorLayer name="behavior_layer1">
                  <BehaviorKeyframe name="keyframe1" index="1">
                    <Diagram>
                      <Box name="Record Sound" id="3" localization="8" tooltip='Record a sound on the robot. You can choose to record only with one&#x0A;microphone (the front head microphone) in ogg format, or with four microphones&#x0A;(front, sides and rear head microphones) in wav format.&#x0A;&#x0A;If &quot;Temporary storage&quot; isn&apos;t checked, the output sound file is located in &quot;~/recordings/microphones/&lt;File name&gt;&quot;.&#x0A;Else, it is located in a temporary directory&#x0A;&#x0A;The onStopped output is stimulated at the end of the recording and contains the absolute path to the output sound file&#x0A;&#x0A;V1.1.0&#x0A;' x="570" y="295">
                        <bitmap>media/images/box/interaction/rec_sound.png</bitmap>
                        <script language="4">
                          <content>
                            <![CDATA[]]>
                          </content>
                        </script>
                        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Launches the recording of the sound." id="2" />
                        <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stops the recording of the sound." id="3" />
                        <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Returns the absolute path of the output sound file at the end of the recording" id="4" />
                        <Parameter name="File name" inherits_from_parent="0" content_type="3" value="recording" default_value="recording" custom_choice="0" tooltip="Name of the destination file without its extension." id="5" />
                        <Parameter name="Microphones used" inherits_from_parent="0" content_type="3" value="Front, sides and rear head microphones (.wav)" default_value="Front, sides and rear head microphones (.wav)" custom_choice="0" tooltip="Microphones used to record the sound.&#x0A;&#x0A;Note: If you use only the front head microphone the file will be saved in ogg format. If you use the&#x0A;front, sides and rear head microphones it will be saved in wav format." id="6">
                          <Choice value="Front head microphone only (.ogg)" />
                          <Choice value="Front, sides and rear head microphones (.wav)" />
                        </Parameter>
                        <Parameter name="Temporary storage" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Choose if the file should be stored as a temporary file so it is removed as soon&#x0A;as the behavior is unloaded.&#x0A;&#x0A;When this option is disabled the file is stored in ~/recordings/microphones. You can&#x0A;then get it on your computer using the menu Connection/File transfer.&#x0A;&#x0A;When this option is enabled the file is stored in the temporary folder of the behavior." id="7" />
                        <Parameter name="Timeout (s)" inherits_from_parent="0" content_type="2" value="5" default_value="5" min="0.1" max="60" tooltip="Duration of the recording in seconds." id="8" />
                        <Timeline enable="0">
                          <BehaviorLayer name="behavior_layer1">
                            <BehaviorKeyframe name="keyframe1" index="1">
                              <Diagram>
                                <Box name="Rec. Sound File" id="4" localization="8" tooltip="Record a sound on the robot. You can choose to record only with one&#x0A;microphone (the front head microphone) in ogg format, or with four microphones&#x0A;(front, sides and rear head&#x0A;microphones) in wav format." x="562" y="100">
                                  <bitmap>media/images/box/interaction/rec_sound.png</bitmap>
                                  <script language="4">
                                    <content>
                                      <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.filepath = ""

    def onLoad(self):
        try:
            self.ad = self.session().service("ALAudioDevice")
        except Exception as e:
            self.ad = None
            self.logger.error(e)
        self.bIsRecording = False
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False
        if( self.bIsRecording ):
            self.ad.stopMicrophonesRecording()
            self.bIsRecording = False

    def onInput_onStart(self, p):
        if(self.bIsRunning):
            return
        self.bIsRunning = True
        sExtension = self.toExtension( self.getParameter("Microphones used") )
        self.filepath = p + sExtension
        if self.ad:
            self.ad.startMicrophonesRecording( self.filepath )
            self.bIsRecording = True
        else:
            self.logger.warning("No sound recorded")

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped(self.filepath)

    def toExtension(self, sMicrophones):
        if( sMicrophones == "Front head microphone only (.ogg)" ):
            return ".ogg"
        else:
            return ".wav"]]>
                                    </content>
                                  </script>
                                  <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                  <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Launches the recording of the sound. The data received on this input must be the&#x0A;filename of the sound." id="2" />
                                  <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stops the recording of the sound." id="3" />
                                  <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Returns the absolute path of the output sound file at the end of the recording" id="4" />
                                  <Parameter name="Microphones used" inherits_from_parent="1" content_type="3" value="Front, sides and rear head microphones (.wav)" default_value="Front, sides and rear head microphones (.wav)" custom_choice="0" tooltip="Microphones used to record the sound.&#x0A;&#x0A;Note: If you use only the front head microphone the file will be saved in ogg format. If you use the&#x0A;front, sides and rear head microphones it will be saved in wav format." id="5">
                                    <Choice value="Front head microphone only (.ogg)" />
                                    <Choice value="Front, sides and rear head microphones (.wav)" />
                                  </Parameter>
                                </Box>
                                <Box name="Get File Name" id="10" localization="8" tooltip="Use this box to choose an attached file in its parameters. The filename will be sent on&#x0A;the output when the input is stimulated." x="234" y="95">
                                  <bitmap>media/images/box/folder.png</bitmap>
                                  <script language="4">
                                    <content>
                                      <![CDATA[import os
class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        pass

    def onInput_onStart(self):
        if( self.getParameter("Temporary storage") ):
            import tempfile
            path = tempfile.mkdtemp() + "/"
        else:
            path = os.path.expanduser('~') + "/recordings/microphones/"
        self.onStopped( path + self.getParameter("File name") )]]>
                                    </content>
                                  </script>
                                  <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                  <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the filepath on the output." id="2" />
                                  <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The filepath of the selected resource file." id="3" />
                                  <Parameter name="File name" inherits_from_parent="1" content_type="3" value="recording" default_value="" custom_choice="0" tooltip="Name of the file." id="4" />
                                  <Parameter name="Temporary storage" inherits_from_parent="1" content_type="0" value="1" default_value="1" tooltip="Choose if the file should be stored as a temporary file so it is removed as soon&#x0A;as the behavior is unloaded.&#x0A;&#x0A;When this option is enabled the file is stored in ~/.cache/currentChoregrapheBehavior&#x0A;or in ~/.cache/&lt;project_name&gt; when you play the behavior from the&#x0A;behavior manager.&#x0A;&#x0A;When it is disabled the file is stored in ~/recordedSounds. You can&#x0A;then get it on your computer using the menu Connection/File transfer." id="5" />
                                </Box>
                                <Box name="Wait" id="6" localization="8" tooltip="Wait a moment before sending a signal on the output. &#x0A;Can be stopped anytime. &#x0A;Stimulating the input again before output is activated restarts the waiting period.&#x0A;" x="392" y="166">
                                  <bitmap>media/images/box/wait.png</bitmap>
                                  <script language="4">
                                    <content>
                                      <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.waiting = None

    def onUnload(self):
        self.cancelWaiting()

    def triggerOutput(self):
        self.timerOutput()

    def cancelWaiting(self):
        if self.waiting:
            self.waiting.cancel()
        self.waiting = None

    def onInput_onStart(self):
        self.cancelWaiting()
        import qi
        self.waiting = qi.async(self.triggerOutput, delay=int(self.getParameter("Timeout (s)") * 1000 * 1000))

    def onInput_onStop(self):
        if self.getParameter("Trigger timerOutput if cancelled") and self.waiting and self.waiting.isRunning():
            self.timerOutput()
        self.onUnload()]]>
                                    </content>
                                  </script>
                                  <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                  <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Start the Wait box with the configured timeout value." id="2" />
                                  <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stop the wait and stimulate the output." id="3" />
                                  <Output name="timerOutput" type="1" type_size="1" nature="1" inner="0" tooltip="Send a bang once time set in parameters is elapsed, or if the box is stopped and the appropriate parameter is set." id="4" />
                                  <Parameter name="Timeout (s)" inherits_from_parent="1" content_type="2" value="5" default_value="5" min="0.1" max="60" tooltip="Duration the box waits before stimulating the output." id="5" />
                                  <Parameter name="Trigger timerOutput if cancelled" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="If the box is currently waiting and cancelled, output will be stimulated." id="6" />
                                </Box>
                                <Link inputowner="0" indexofinput="4" outputowner="4" indexofoutput="4" />
                                <Link inputowner="10" indexofinput="2" outputowner="0" indexofoutput="2" />
                                <Link inputowner="4" indexofinput="2" outputowner="10" indexofoutput="3" />
                                <Link inputowner="6" indexofinput="2" outputowner="10" indexofoutput="3" />
                                <Link inputowner="4" indexofinput="3" outputowner="6" indexofoutput="4" />
                              </Diagram>
                            </BehaviorKeyframe>
                          </BehaviorLayer>
                        </Timeline>
                        <Resource name="Audio recorder" type="Lock" timeout="0" />
                      </Box>
                      <Box name="Eye LEDs" id="1" localization="8" tooltip="Set the LED color of the eyes. Note that you must open the box to enter the color." x="557" y="521">
                        <bitmap>media/images/box/interaction/LED.png</bitmap>
                        <script language="4">
                          <content>
                            <![CDATA[]]>
                          </content>
                        </script>
                        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                        <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                        <Parameter name="Side" inherits_from_parent="0" content_type="3" value="Both" default_value="Both" custom_choice="0" tooltip="Choose the eye where the LED light is set." id="4">
                          <Choice value="Both" />
                          <Choice value="Left" />
                          <Choice value="Right" />
                        </Parameter>
                        <Parameter name="Duration (s)" inherits_from_parent="0" content_type="2" value="0" default_value="0.1" min="0" max="5" tooltip="Transition&apos;s duration in seconds." id="5" />
                        <Timeline enable="0">
                          <BehaviorLayer name="behavior_layer1">
                            <BehaviorKeyframe name="keyframe1" index="1">
                              <Diagram>
                                <Box name="Eyes LEDs" id="15" localization="8" tooltip="Set the color of LEDs of robot&apos;s eyes." x="281" y="41">
                                  <bitmap>media/images/box/interaction/LED.png</bitmap>
                                  <script language="4">
                                    <content>
                                      <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.fadeOps = []
        self.leds = self.session().service("ALLeds")

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_color(self, p):
        if( self.getParameter("Side") == "Left" ):
            sGroup = "LeftFaceLeds"
        elif( self.getParameter("Side") == "Right" ):
            sGroup = "RightFaceLeds"
        else:
            sGroup = "FaceLeds"
        fadeOp = self.leds.fadeRGB(sGroup, 256*256*p[0] + 256*p[1] + p[2], self.getParameter("Duration (s)"), _async=True)
        self.fadeOps.append(fadeOp)
        fadeOp.wait()
        self.fadeOps.remove(fadeOp)
        if( self.fadeOps == [] ):
            self.onDone() # activate output of the box]]>
                                    </content>
                                  </script>
                                  <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                  <Input name="color" type="2" type_size="3" nature="2" inner="0" tooltip="Color of robot&apos;s eyes." id="2" />
                                  <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                                  <Parameter name="Side" inherits_from_parent="1" content_type="3" value="Both" default_value="Both" custom_choice="0" tooltip="Choose the eye where the LED light is set." id="4">
                                    <Choice value="Both" />
                                    <Choice value="Left" />
                                    <Choice value="Right" />
                                  </Parameter>
                                  <Parameter name="Duration (s)" inherits_from_parent="1" content_type="2" value="0.1" default_value="0.1" min="0" max="5" tooltip="Transition&apos;s duration in seconds." id="5" />
                                </Box>
                                <Box name="Color Edit" id="16" localization="8" tooltip="Transmit a table of number [R,G,B] correponsding to the selected color." plugin="coloredit_plugin" x="105" y="47">
                                  <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                  <script language="4">
                                    <content>
                                      <![CDATA[class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped([128, 255, 7])]]>
                                    </content>
                                  </script>
                                  <pluginContent>
                                    <color>#80ff07</color>
                                  </pluginContent>
                                  <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                  <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="To send the color on the output." id="2" />
                                  <Output name="onStopped" type="2" type_size="3" nature="1" inner="0" tooltip="[R,G,B] with R, G and B between 0 and 255." id="3" />
                                </Box>
                                <Link inputowner="15" indexofinput="2" outputowner="16" indexofoutput="3" />
                                <Link inputowner="16" indexofinput="2" outputowner="0" indexofoutput="2" />
                                <Link inputowner="0" indexofinput="3" outputowner="15" indexofoutput="3" />
                              </Diagram>
                            </BehaviorKeyframe>
                          </BehaviorLayer>
                        </Timeline>
                      </Box>
                      <Link inputowner="3" indexofinput="2" outputowner="0" indexofoutput="2" />
                      <Link inputowner="0" indexofinput="3" outputowner="3" indexofoutput="4" />
                      <Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" />
                    </Diagram>
                  </BehaviorKeyframe>
                </BehaviorLayer>
              </Timeline>
            </Box>
            <Box name="Foutmelding spreken" id="3" localization="8" tooltip="Say the text received on its input." x="1073" y="58">
              <bitmap>media/images/box/interaction/say.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.tts = self.session().service('ALTextToSpeech')
        self.ttsStop = self.session().service('ALTextToSpeech') #Create another service as wait is blocking if audioout is remote
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.pCall("say",str(sentence))
            self.ids.append(id)
            self.tts.wait(id)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
              <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
              <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
              <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
              <Resource name="Speech" type="Lock" timeout="0" />
            </Box>
            <Link inputowner="2" indexofinput="2" outputowner="1" indexofoutput="5" />
            <Link inputowner="7" indexofinput="2" outputowner="2" indexofoutput="4" />
            <Link inputowner="4" indexofinput="2" outputowner="7" indexofoutput="3" />
            <Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" />
            <Link inputowner="0" indexofinput="4" outputowner="4" indexofoutput="5" />
            <Link inputowner="1" indexofinput="4" outputowner="4" indexofoutput="4" />
            <Link inputowner="0" indexofinput="4" outputowner="3" indexofoutput="4" />
            <Link inputowner="3" indexofinput="2" outputowner="4" indexofoutput="6" />
            <Link inputowner="3" indexofinput="2" outputowner="1" indexofoutput="6" />
          </Diagram>
        </BehaviorKeyframe>
      </BehaviorLayer>
    </Timeline>
  </Box>
</ChoregrapheProject>
